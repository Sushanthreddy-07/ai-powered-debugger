{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfec7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['after_merge', 'before_merge', 'filename', 'full_file_code_after_merge',\n",
      "       'full_file_code_before_merge', 'function_name', 'url',\n",
      "       'source code and errors', 'full_traceback', 'traceback_type',\n",
      "       'before_merge_without_docstrings', 'after_merge_without_docstrings',\n",
      "       'before_merge_docstrings', 'after_merge_docstrings',\n",
      "       'path_to_snippet_before_merge', 'path_to_snippet_after_merge'],\n",
      "      dtype='object')\n",
      "(14118, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "df = pd.read_pickle(r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\buggy_dataset\\bugfixes_train.pickle\")\n",
    "print(df.columns)\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ec0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the buggy code\n",
    "buggy_cls_df = df[['before_merge']].copy()\n",
    "buggy_cls_df = buggy_cls_df.rename(columns={'before_merge': 'code'})\n",
    "buggy_cls_df['label'] = 1  # Mark as buggy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286eef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_buggy_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"latin1\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[['before_merge']].copy()\n",
    "    df = df.rename(columns={'before_merge': 'code'})\n",
    "    df['label'] = 1\n",
    "    return df\n",
    "\n",
    "# Paths to val/test buggy data\n",
    "buggy_val_path = r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\buggy_dataset\\bugfixes_valid.pickle\"\n",
    "buggy_test_path = r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\buggy_dataset\\bugfixes_test.pickle\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_buggy_pickle(path):\n",
    "    df = pd.read_pickle(path)\n",
    "    print(f\"Loaded {len(df)} rows from {path}\")\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf09fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9457 rows from C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\buggy_dataset\\bugfixes_valid.pickle\n",
      "Loaded 161 rows from C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\buggy_dataset\\bugfixes_test.pickle\n"
     ]
    }
   ],
   "source": [
    "buggy_val_df = load_buggy_pickle(buggy_val_path)\n",
    "buggy_test_df = load_buggy_pickle(buggy_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f74b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine all buggy\n",
    "all_buggy_df = pd.concat([buggy_cls_df, buggy_val_df, buggy_test_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea481192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['before_merge', 'repo_name', 'filename', 'function_name',\n",
      "       'path_to_source_file', 'commit', 'path_to_snippet_before_merge',\n",
      "       'times'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "stable_path = r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\stable_dataset\\stable_code_train.pickle\"\n",
    "\n",
    "with open(stable_path, \"rb\") as f:\n",
    "    stable_data = pd.read_pickle(f)\n",
    "\n",
    "stable_df = pd.DataFrame(stable_data)\n",
    "print(stable_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d048a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'before_merge' as the clean code column\n",
    "stable_cls_df = stable_df[['before_merge']].copy()\n",
    "stable_cls_df = stable_cls_df.rename(columns={'before_merge': 'code'})\n",
    "stable_cls_df['label'] = 0  # Mark as clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233e13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stable_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pd.read_pickle(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[['before_merge']].copy()\n",
    "    df = df.rename(columns={'before_merge': 'code'})\n",
    "    df['label'] = 0\n",
    "    return df\n",
    "\n",
    "# Paths\n",
    "val_path = r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\stable_dataset\\stable_code_valid.pickle\"\n",
    "test_path = r\"C:\\Users\\susha\\OneDrive\\Desktop\\ai debugger\\stable_dataset\\stable_code_test.pickle\"\n",
    "\n",
    "# Load remaining stable data\n",
    "stable_val_df = load_stable_pickle(val_path)\n",
    "stable_test_df = load_stable_pickle(test_path)\n",
    "\n",
    "# Combine all clean code\n",
    "all_stable_df = pd.concat([stable_cls_df, stable_val_df, stable_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a952819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    2655238\n",
      "1.0      14118\n",
      "Name: count, dtype: int64\n",
      "                                                      code  label after_merge  \\\n",
      "1596892  b'    def redraw(self, *args):\\n        self.d...    0.0         NaN   \n",
      "1191105  b'    def command(self):\\n        \"\"\"The comma...    0.0         NaN   \n",
      "724202   b'    def __call__(self, data):\\n        if is...    0.0         NaN   \n",
      "599775   b\"def downgrade():\\n    '''\\n    Downgrade the...    0.0         NaN   \n",
      "777538   b'    def remove_all(self):\\n        \"\"\"\\n    ...    0.0         NaN   \n",
      "\n",
      "        before_merge filename full_file_code_after_merge  \\\n",
      "1596892          NaN      NaN                        NaN   \n",
      "1191105          NaN      NaN                        NaN   \n",
      "724202           NaN      NaN                        NaN   \n",
      "599775           NaN      NaN                        NaN   \n",
      "777538           NaN      NaN                        NaN   \n",
      "\n",
      "        full_file_code_before_merge function_name  url source code and errors  \\\n",
      "1596892                         NaN           NaN  NaN                    NaN   \n",
      "1191105                         NaN           NaN  NaN                    NaN   \n",
      "724202                          NaN           NaN  NaN                    NaN   \n",
      "599775                          NaN           NaN  NaN                    NaN   \n",
      "777538                          NaN           NaN  NaN                    NaN   \n",
      "\n",
      "         ... after_merge_without_docstrings before_merge_docstrings  \\\n",
      "1596892  ...                            NaN                     NaN   \n",
      "1191105  ...                            NaN                     NaN   \n",
      "724202   ...                            NaN                     NaN   \n",
      "599775   ...                            NaN                     NaN   \n",
      "777538   ...                            NaN                     NaN   \n",
      "\n",
      "        after_merge_docstrings path_to_snippet_before_merge  \\\n",
      "1596892                    NaN                          NaN   \n",
      "1191105                    NaN                          NaN   \n",
      "724202                     NaN                          NaN   \n",
      "599775                     NaN                          NaN   \n",
      "777538                     NaN                          NaN   \n",
      "\n",
      "        path_to_snippet_after_merge bug type bug description bug filename  \\\n",
      "1596892                         NaN      NaN             NaN          NaN   \n",
      "1191105                         NaN      NaN             NaN          NaN   \n",
      "724202                          NaN      NaN             NaN          NaN   \n",
      "599775                          NaN      NaN             NaN          NaN   \n",
      "777538                          NaN      NaN             NaN          NaN   \n",
      "\n",
      "        bug function_name bug lines  \n",
      "1596892               NaN       NaN  \n",
      "1191105               NaN       NaN  \n",
      "724202                NaN       NaN  \n",
      "599775                NaN       NaN  \n",
      "777538                NaN       NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "def get_webapp_settings(name, site, settings):\n",
      "    r\"\"\"\n",
      "    .. versionadded:: 2017.7.0\n",
      "\n",
      "    Get the value of the setting for the IIS web application.\n",
      "\n",
      "    .. note::\n",
      "        Params are case sensitive\n",
      "\n",
      "    :param str name: The name of the IIS web application.\n",
      "    :param str site: The site name contains the web application.\n",
      "        Example: Default Web Site\n",
      "    :param str settings: A dictionary of the setting names and their values.\n",
      "        Available settings: physicalPath, applicationPool, userName, password\n",
      "    Returns:\n",
      "        dict: A dictionary of the provided settings and their values.\n",
      "\n",
      "    CLI Example:\n",
      "\n",
      "    .. code-block:: bash\n",
      "\n",
      "        salt '*' win_iis.get_webapp_settings name='app0' site='Default Web Site'\n",
      "            settings=\"['physicalPath','applicationPool']\"\n",
      "    \"\"\"\n",
      "    ret = dict()\n",
      "    pscmd = list()\n",
      "    availableSettings = (\"physicalPath\", \"applicationPool\", \"userName\", \"password\")\n",
      "\n",
      "    if not settings:\n",
      "        log.warning(\"No settings provided\")\n",
      "        return ret\n",
      "\n",
      "    pscmd.append(r\"$Settings = @{};\")\n",
      "\n",
      "    # Verify setting is ine predefined settings and append relevant query command per setting key\n",
      "    for setting in settings:\n",
      "        if setting in availableSettings:\n",
      "            if setting == \"userName\" or setting == \"password\":\n",
      "                pscmd.append(\n",
      "                    \" $Property = Get-WebConfigurationProperty -Filter \\\"system.applicationHost/sites/site[@name='{}']/application[@path='/{}']/virtualDirectory[@path='/']\\\"\".format(\n",
      "                        site, name\n",
      "                    )\n",
      "                )\n",
      "                pscmd.append(\n",
      "                    r' -Name \"{}\" -ErrorAction Stop | select Value;'.format(setting)\n",
      "                )\n",
      "                pscmd.append(\n",
      "                    r\" $Property = $Property | Select-Object -ExpandProperty Value;\"\n",
      "                )\n",
      "                pscmd.append(r\" $Settings['{}'] = [String] $Property;\".format(setting))\n",
      "                pscmd.append(r\" $Property = $Null;\")\n",
      "\n",
      "            if setting == \"physicalPath\" or setting == \"applicationPool\":\n",
      "                pscmd.append(\n",
      "                    r\" $Property = (get-webapplication {}).{};\".format(name, setting)\n",
      "                )\n",
      "                pscmd.append(r\" $Settings['{}'] = [String] $Property;\".format(setting))\n",
      "                pscmd.append(r\" $Property = $Null;\")\n",
      "\n",
      "        else:\n",
      "            availSetStr = \", \".join(availableSettings)\n",
      "            message = (\n",
      "                \"Unexpected setting:\"\n",
      "                + setting\n",
      "                + \". Available settings are: \"\n",
      "                + availSetStr\n",
      "            )\n",
      "            raise SaltInvocationError(message)\n",
      "\n",
      "    pscmd.append(\" $Settings\")\n",
      "    # Run commands and return data as json\n",
      "    cmd_ret = _srvmgr(cmd=\"\".join(pscmd), return_json=True)\n",
      "\n",
      "    # Update dict var to return data\n",
      "    try:\n",
      "        items = salt.utils.json.loads(cmd_ret[\"stdout\"], strict=False)\n",
      "\n",
      "        if isinstance(items, list):\n",
      "            ret.update(items[0])\n",
      "        else:\n",
      "            ret.update(items)\n",
      "    except ValueError:\n",
      "        log.error(\"Unable to parse return data as Json.\")\n",
      "\n",
      "    if None in ret.values():\n",
      "        message = \"Some values are empty - please validate site and web application names. Some commands are case sensitive\"\n",
      "        raise SaltInvocationError(message)\n",
      "\n",
      "    return ret\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine and shuffle\n",
    "combined_df_all = pd.concat([all_buggy_df, all_stable_df], ignore_index=True)\n",
    "combined_df_all = combined_df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(combined_df_all['label'].value_counts())\n",
    "print(combined_df_all.sample(5))\n",
    "\n",
    "\n",
    "# Decode any byte strings\n",
    "combined_df_all['code'] = combined_df_all['code'].apply(\n",
    "    lambda x: x.decode('utf-8', errors='ignore') if isinstance(x, bytes) else x\n",
    ")\n",
    "\n",
    "# Preview\n",
    "print(combined_df_all.sample(3)['code'].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cecec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af149ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts (after cleaning):\n",
      "label\n",
      "0    2655238\n",
      "1      14118\n",
      "Name: count, dtype: int64\n",
      "(2135484,) (533872,) label\n",
      "0    2124190\n",
      "1      11294\n",
      "Name: count, dtype: int64 label\n",
      "0    531048\n",
      "1      2824\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Ensure 'code' exists and is string; ensure 'label' exists\n",
    "assert 'code' in combined_df_all.columns, \"Missing 'code' column\"\n",
    "assert 'label' in combined_df_all.columns, \"Missing 'label' column\"\n",
    "\n",
    "# 2) Normalize label values to {0,1} and drop NaNs\n",
    "#    (handles cases like 'buggy'/'clean', True/False, etc.)\n",
    "label_map = {\n",
    "    'buggy': 1, 'Buggy': 1, 'BUGGY': 1, True: 1, 1: 1,\n",
    "    'clean': 0, 'stable': 0, 'Clean': 0, 'STABLE': 0, False: 0, 0: 0\n",
    "}\n",
    "combined_df_all['label'] = combined_df_all['label'].map(label_map).astype('float')  # map unknowns to NaN\n",
    "\n",
    "# 3) Basic cleaning\n",
    "combined_df_all['code'] = combined_df_all['code'].astype(str)\n",
    "combined_df_all = combined_df_all.dropna(subset=['code', 'label']).copy()\n",
    "\n",
    "# 4) Optional: drop empties/whitespace-only code\n",
    "combined_df_all = combined_df_all[combined_df_all['code'].str.strip().ne('')]\n",
    "\n",
    "# 5) Make labels integer\n",
    "combined_df_all['label'] = combined_df_all['label'].astype(int)\n",
    "\n",
    "# 6) Quick sanity checks\n",
    "print(\"Label counts (after cleaning):\")\n",
    "print(combined_df_all['label'].value_counts(dropna=False))\n",
    "assert set(combined_df_all['label'].unique()) <= {0,1}, \"Labels must be 0/1 only\"\n",
    "\n",
    "# 7) If either class is too small, adjust stratify usage\n",
    "min_class = combined_df_all['label'].value_counts().min()\n",
    "\n",
    "X = combined_df_all['code'].reset_index(drop=True)\n",
    "y = combined_df_all['label'].reset_index(drop=True)\n",
    "\n",
    "if min_class < 2:\n",
    "    # Not enough samples to stratify; fall back to regular split\n",
    "    print(\"‚ö†Ô∏è Too few samples in one class for stratify. Falling back to non-stratified split.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    # Safe to stratify\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.value_counts(), y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d73c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_df_all['code'], \n",
    "    combined_df_all['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=combined_df_all['label'], \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a322a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w+',\n",
    "    ngram_range=(1, 2),  # unigrams + bigrams\n",
    "    max_features=50000\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba30b437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "311e5b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9978    0.9411    0.9686    531048\n",
      "           1     0.0524    0.6133    0.0966      2824\n",
      "\n",
      "    accuracy                         0.9393    533872\n",
      "   macro avg     0.5251    0.7772    0.5326    533872\n",
      "weighted avg     0.9928    0.9393    0.9640    533872\n",
      "\n",
      "üî¢ Confusion Matrix:\n",
      "[[499757  31291]\n",
      " [  1092   1732]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"üîç Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"üî¢ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f18661ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9950    0.9996    0.9973    531048\n",
      "           1     0.4278    0.0598    0.1050      2824\n",
      "\n",
      "    accuracy                         0.9946    533872\n",
      "   macro avg     0.7114    0.5297    0.5511    533872\n",
      "weighted avg     0.9920    0.9946    0.9926    533872\n",
      "\n",
      "[[530822    226]\n",
      " [  2655    169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f05fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\susha\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:54:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    531048\n",
      "           1       0.02      0.64      0.04      2824\n",
      "\n",
      "    accuracy                           0.84    533872\n",
      "   macro avg       0.51      0.74      0.48    533872\n",
      "weighted avg       0.99      0.84      0.91    533872\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[445441  85607]\n",
      " [  1010   1814]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Install if needed (uncomment below if not installed)\n",
    "# !pip install xgboost\n",
    "\n",
    "# 2. Import\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 3. Train XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(), \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_xgb = xgb.predict(X_test_tfidf)\n",
    "\n",
    "# 5. Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
